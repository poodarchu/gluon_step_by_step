{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import ndarray as nd\n",
    "from mxnet import autograd as ag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 2\n",
    "num_examples = 1000\n",
    "\n",
    "true_w = [2, -3.4]\n",
    "true_b = 4.2\n",
    "\n",
    "X = nd.random_normal(shape=(num_examples, num_inputs))\n",
    "y = true_w[0] * X[:,0] + true_w[1] * X[:, 1] + true_b\n",
    "y += 0.01 * nd.random_normal(shape=y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ 1.16307867  0.48380461]\n",
      "<NDArray 2 @cpu(0)> \n",
      "[ 4.87962484]\n",
      "<NDArray 1 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "print(X[0], y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10fc67550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X[:, 1].asnumpy(), y.asnumpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过 Python 的 yeild 构造一个 iterator\n",
    "import random\n",
    "batch_size = 32\n",
    "def data_iter():\n",
    "    idx = list(range(num_examples))\n",
    "    random.shuffle(idx)\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        j = nd.array(idx[i:min(i+batch_size, num_examples)])\n",
    "        yield nd.take(X, j), nd.take(y, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[-0.72485566  1.11196363]\n",
      " [ 1.60673869  0.18408279]\n",
      " [ 0.22842942  0.62486178]\n",
      " [-0.93251252  2.05497503]\n",
      " [-1.50477183 -0.05162206]\n",
      " [-1.46828771  0.56517828]\n",
      " [ 1.17471194  1.36774385]\n",
      " [ 0.43260059  0.94352221]\n",
      " [-0.2103665  -2.23908734]\n",
      " [ 1.4021405  -2.4169414 ]\n",
      " [ 0.44712451  0.28236011]\n",
      " [-2.77867079  0.01066511]\n",
      " [-0.36942869  0.54585946]\n",
      " [-1.05003417  1.45409334]\n",
      " [ 1.17235053  1.52714729]\n",
      " [ 0.57125562 -1.57108414]\n",
      " [ 1.7005018   0.25498316]\n",
      " [ 0.11150214 -0.22487849]\n",
      " [-1.05367899 -0.26470137]\n",
      " [-0.25803244  0.02452744]\n",
      " [ 1.45263755  2.13133287]\n",
      " [-0.66490102  0.50258273]\n",
      " [-0.69040912  0.09003334]\n",
      " [ 0.300295    0.73225945]\n",
      " [-0.48599643 -1.13515449]\n",
      " [-0.29419237 -0.239079  ]\n",
      " [ 0.425275   -0.37855875]\n",
      " [-0.68288445 -0.25153375]\n",
      " [ 0.46851122  0.81799328]\n",
      " [ 0.00585518 -0.32527655]\n",
      " [ 0.25081477 -0.30159083]\n",
      " [ 0.80678338 -0.55400944]]\n",
      "<NDArray 32x2 @cpu(0)> \n",
      "[ -1.02687657   6.79803848   2.51352644  -4.65387917   1.35681796\n",
      "  -0.63820291   1.92082524   1.8577776   11.38772964  15.22098064\n",
      "   4.11079836  -1.39621007   1.59425259  -2.84352398   1.34656918\n",
      "  10.67247581   6.73640919   5.19164181   2.9900887    3.60681534\n",
      "  -0.13999587   1.17576194   2.51088953   2.31624866   7.0977335\n",
      "   4.42777824   6.33143234   3.6914947    2.34939742   5.33057404\n",
      "   5.74482155   7.70352411]\n",
      "<NDArray 32 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "for data, label in data_iter():\n",
    "    print(data, label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = nd.random_normal(shape=(num_inputs, 1))\n",
    "b = nd.zeros((1,))\n",
    "params = [w, b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in params:\n",
    "    param.attach_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net(X):\n",
    "    return nd.dot(X, w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_loss(y_hat, y):\n",
    "    return (y_hat-y)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(params, lr):\n",
    "    for param in params:\n",
    "        param[:] = param - lr * param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型函数\n",
    "def real_fn(X):\n",
    "    return 2 * X[:, 0] - 3.4 * X[:, 1] + 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制损失随训练次数降低的折线图，以及预测值和真实值的散点图\n",
    "def plot(losses, X, sample_size=100):\n",
    "    xs = list(range(len(losses)))\n",
    "    f, (fg1, fg2) = plt.subplots(1, 2)\n",
    "    fg1.set_title('Loss during training')\n",
    "    fg1.plot(xs, losses, '-r')\n",
    "    fg2.set_title('Estimated vs real function')\n",
    "    fg2.plot(X[:sample_size, 1].asnumpy(),\n",
    "             net(X[:sample_size, :]).asnumpy(), 'or', label='Estimated')\n",
    "    fg2.plot(X[:sample_size, 1].asnumpy(),\n",
    "             real_fn(X[:sample_size, :]).asnumpy(), '*g', label='Real')\n",
    "    fg2.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "learning_rate = .001\n",
    "niter = 0\n",
    "losses = []\n",
    "moving_loss = 0.\n",
    "smoothing_constant = .01\n",
    "\n",
    "# 训练\n",
    "for e in range(epochs):\n",
    "    total_loss = 0.\n",
    "\n",
    "    for data, label in data_iter():\n",
    "        with ag.record():\n",
    "            output = net(data)\n",
    "            loss = square_loss(output, label)\n",
    "        loss.backward()\n",
    "        SGD(params, learning_rate)\n",
    "        total_loss += nd.sum(loss).asscalar()\n",
    "\n",
    "        # 记录每读取一个数据点后，损失的移动平均值的变化；\n",
    "        niter +=1\n",
    "        curr_loss = nd.mean(loss).asscalar()\n",
    "        moving_loss = (1 - smoothing_constant) * moving_loss + (smoothing_constant) * curr_loss\n",
    "\n",
    "        # correct the bias from the moving averages\n",
    "        est_loss = moving_loss/(1-(1-smoothing_constant)**niter)\n",
    "\n",
    "        if (niter + 1) % 100 == 0:\n",
    "            losses.append(est_loss)\n",
    "            print(\"Epoch %s, batch %s. Moving avg of loss: %s. Average loss: %f\" % (e, niter, est_loss, total_loss/num_examples))\n",
    "            plot(losses, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, -3.4] \n",
      "[[  1.00215664e+16]\n",
      " [ -1.38553229e+14]]\n",
      "<NDArray 2x1 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "print(true_w, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2 \n",
      "[ -8.28094928e+15]\n",
      "<NDArray 1 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "print(true_b, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
